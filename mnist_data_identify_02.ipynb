{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "# import mnist data from tensorflow\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use code from \"mnist_data_identify_simple\"\n",
    "\n",
    "## this time, change \"Optimizer\" to train model\n",
    "\n",
    "many optimizer method provided on:\n",
    "https://www.tensorflow.org/api_docs/python/tf/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 0,Testing Accuracy 0.9203\n",
      "Iter 1,Testing Accuracy 0.9262\n",
      "Iter 2,Testing Accuracy 0.9271\n",
      "Iter 3,Testing Accuracy 0.927\n",
      "Iter 4,Testing Accuracy 0.9282\n",
      "Iter 5,Testing Accuracy 0.9288\n",
      "Iter 6,Testing Accuracy 0.931\n",
      "Iter 7,Testing Accuracy 0.9278\n",
      "Iter 8,Testing Accuracy 0.9316\n",
      "Iter 9,Testing Accuracy 0.9275\n",
      "Iter 10,Testing Accuracy 0.93\n",
      "Iter 11,Testing Accuracy 0.9282\n",
      "Iter 12,Testing Accuracy 0.9309\n",
      "Iter 13,Testing Accuracy 0.9316\n",
      "Iter 14,Testing Accuracy 0.9291\n",
      "Iter 15,Testing Accuracy 0.9319\n",
      "Iter 16,Testing Accuracy 0.9302\n",
      "Iter 17,Testing Accuracy 0.9298\n",
      "Iter 18,Testing Accuracy 0.9282\n",
      "Iter 19,Testing Accuracy 0.9308\n",
      "Iter 20,Testing Accuracy 0.9304\n"
     ]
    }
   ],
   "source": [
    "# get mnist data set & store in current folder, rename it 'MNIST_data'\n",
    "# A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. \n",
    "# In this case, the nth digit will be represented as a vector which is 1 in the nth dimension.\n",
    "# For example, 3 would be [0,0,0,1,0,0,0,0,0,0]\n",
    "mnist = input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "\n",
    "# set batch_size, every time put 100 images for training\n",
    "batch_size = 100\n",
    "# calculate number of batches from data set\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "# define two placehoder\n",
    "x = tf.placeholder(tf.float32,[None,784]) #images  784 = 28 * 28 pixels\n",
    "y = tf.placeholder(tf.float32,[None,10])  #labels  10 stands for 0~9\n",
    "\n",
    "# define a nural network              \n",
    "# tf.zeros -> initial value is 0\n",
    "# W has a shape of [784, 10] because we want to multiply the 784-dimensional image vectors by it \n",
    "# to produce 10-dimensional vectors of evidence for the difference classes. \n",
    "W = tf.Variable(tf.zeros([784,10])) \n",
    "b = tf.Variable(tf.zeros([10]))     # b:bisa, has a shape of [10] so we can add it to the output.\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "# calculate cost(loss), and minimize loss\n",
    "#     use  quadratic cost method --fomular (y-mx-b)^2      # suit for linear\n",
    "#     loss = tf.reduce_mean(tf.square(y-prediction))  # suit for s-shape\n",
    "# use cross_entropy method: tf.nn.softmax_cross_entropy_with_logits method\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "# ------------------------------------------------------------------------------modified--------\n",
    "# use GradientDescent to train\n",
    "#train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "# use different Optimizer\n",
    "train_step = tf.train.AdamOptimizer(1e-2).minimize(loss)   # 1e-2 = 10^-2 = 0.02\n",
    "\n",
    "# initial glabal variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1)) # correct return true, otherwise return false\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # true->1.0   false->0\n",
    "\n",
    "# create loop to train\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for eposh in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,{x:batch_xs, y:batch_ys})\n",
    "# calculate accuracy\n",
    "        acc = sess.run(accuracy,{x:mnist.test.images, y:mnist.test.labels})\n",
    "        print(\"Iter \" + str(eposh) + \",Testing Accuracy \" + str(acc))\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## result of using GradientDescentOptimizer :\n",
    "Iter 0,Testing Accuracy 0.8246\n",
    "Iter 1,Testing Accuracy 0.8939\n",
    "Iter 2,Testing Accuracy 0.9026\n",
    "Iter 3,Testing Accuracy 0.9057\n",
    "Iter 4,Testing Accuracy 0.908\n",
    "Iter 5,Testing Accuracy 0.9101\n",
    "Iter 6,Testing Accuracy 0.9121\n",
    "Iter 7,Testing Accuracy 0.9137\n",
    "Iter 8,Testing Accuracy 0.9146\n",
    "Iter 9,Testing Accuracy 0.9156\n",
    "Iter 10,Testing Accuracy 0.9167\n",
    "Iter 11,Testing Accuracy 0.9187\n",
    "Iter 12,Testing Accuracy 0.9198\n",
    "Iter 13,Testing Accuracy 0.9192\n",
    "Iter 14,Testing Accuracy 0.9206\n",
    "Iter 15,Testing Accuracy 0.9199\n",
    "Iter 16,Testing Accuracy 0.9209\n",
    "Iter 17,Testing Accuracy 0.9208\n",
    "Iter 18,Testing Accuracy 0.9207\n",
    "Iter 19,Testing Accuracy 0.9207\n",
    "Iter 20,Testing Accuracy 0.9211\n",
    "\n",
    "## result of using AdadeltaOptimizer :\n",
    "Iter 0,Testing Accuracy 0.6596\n",
    "Iter 1,Testing Accuracy 0.6608\n",
    "Iter 2,Testing Accuracy 0.6652\n",
    "Iter 3,Testing Accuracy 0.6756\n",
    "Iter 4,Testing Accuracy 0.6894\n",
    "Iter 5,Testing Accuracy 0.7027\n",
    "Iter 6,Testing Accuracy 0.7163\n",
    "Iter 7,Testing Accuracy 0.7238\n",
    "Iter 8,Testing Accuracy 0.7318\n",
    "Iter 9,Testing Accuracy 0.734\n",
    "Iter 10,Testing Accuracy 0.7375\n",
    "Iter 11,Testing Accuracy 0.7414\n",
    "Iter 12,Testing Accuracy 0.744\n",
    "Iter 13,Testing Accuracy 0.7486\n",
    "Iter 14,Testing Accuracy 0.7517\n",
    "Iter 15,Testing Accuracy 0.754\n",
    "Iter 16,Testing Accuracy 0.7581\n",
    "Iter 17,Testing Accuracy 0.7608\n",
    "Iter 18,Testing Accuracy 0.7638\n",
    "Iter 19,Testing Accuracy 0.767\n",
    "Iter 20,Testing Accuracy 0.7695\n",
    "\n",
    "# result of using AdamOptimizer :\n",
    "Iter 0,Testing Accuracy 0.9203\n",
    "Iter 1,Testing Accuracy 0.9262\n",
    "Iter 2,Testing Accuracy 0.9271\n",
    "Iter 3,Testing Accuracy 0.927\n",
    "Iter 4,Testing Accuracy 0.9282\n",
    "Iter 5,Testing Accuracy 0.9288\n",
    "Iter 6,Testing Accuracy 0.931\n",
    "Iter 7,Testing Accuracy 0.9278\n",
    "Iter 8,Testing Accuracy 0.9316\n",
    "Iter 9,Testing Accuracy 0.9275\n",
    "Iter 10,Testing Accuracy 0.93\n",
    "Iter 11,Testing Accuracy 0.9282\n",
    "Iter 12,Testing Accuracy 0.9309\n",
    "Iter 13,Testing Accuracy 0.9316\n",
    "Iter 14,Testing Accuracy 0.9291\n",
    "Iter 15,Testing Accuracy 0.9319\n",
    "Iter 16,Testing Accuracy 0.9302\n",
    "Iter 17,Testing Accuracy 0.9298\n",
    "Iter 18,Testing Accuracy 0.9282\n",
    "Iter 19,Testing Accuracy 0.9308\n",
    "Iter 20,Testing Accuracy 0.9304"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
